(*/ω＼*)<hr /><p>API的压力测试是业务上线前的重要环节，也是对系统性能的一个量化测量，对实际业务诸方面都有重要的参考价值。</p><p>这里主要说说API压测的方法和常用手段。</p><h2 id="压测方法"><a href="#压测方法" class="headerlink" title="压测方法"></a>压测方法</h2><ul><li>go benchmark</li></ul><p>如果是golang后端，可以直接手写测试用例，然后使用go工具链自带的benchmark进行压测。</p><ul><li>ApacheBench</li></ul><p>ab命令会创建多个并发访问线程，模拟多个访问者同时对某一URL地址进行访问。</p><p>安装<code>apache2-utils</code>即可在系统上使用<code>ab</code>命令。</p><p>作为演示，使用ab测试一个GET接口：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ab -n 2000 -c 1200  <span class="string">&quot;http://127.0.0.1:9999/get_result?a=10&amp;b=20&quot;</span></span><br></pre></td></tr></table></figure><ul><li><p>n: 测试轮次</p></li><li><p>c: 客户端数量</p></li><li><p>T: 内容类型</p></li><li><p>p: 包含post参数的文件</p></li><li><p>引号是必须的</p></li><li><p>wrk</p></li></ul><p>一个C编写的API压测工具</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wrk -t10 -c100 -d10s http://localhost:8080/api/users    <span class="comment"># 使用10个线程，100并发数，测试持续10s</span></span><br></pre></td></tr></table></figure><h2 id="开测"><a href="#开测" class="headerlink" title="开测"></a>开测</h2><p>我最后还是选了<code>wrk</code>做压测<del>因为ab装不上</del></p><p>测试接口是<code>POST http://localhost:8080/api/calc/mul</code>，payload是一个2*n的json格式的二维数组。</p><p>测试指令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">wrk -t 20 -c 10000 -d 180s -s bench.lua --latency <span class="string">&quot;http://localhost:8080/api/calc/mul&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## bench.lua</span></span><br><span class="line">wrk.method = <span class="string">&quot;POST&quot;</span></span><br><span class="line">wrk.body = <span class="string">&quot;[[1,2,3,1],[4,5,7,8]]&quot;</span></span><br><span class="line">wrk.headers[<span class="string">&#x27;Content-Type&#x27;</span>] = <span class="string">&quot;application/json&quot;</span></span><br></pre></td></tr></table></figure><p>测试结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">xeonds@ark-station:~/code/vec-calculator-server$ make bench </span><br><span class="line"><span class="built_in">cd</span> build &amp;&amp; ./vec-calc-web-linux-amd64-1.0.0 &amp; <span class="built_in">sleep</span> 1 &amp;&amp; \</span><br><span class="line">wrk -t 20 -c 10000 -d 180s -s bench.lua --latency <span class="string">&quot;http://localhost:8080/api/calc/mul&quot;</span></span><br><span class="line">Running 3m <span class="built_in">test</span> @ http://localhost:8080/api/calc/mul</span><br><span class="line">  20 threads and 10000 connections</span><br><span class="line">  Thread Stats   Avg      Stdev     Max   +/- Stdev</span><br><span class="line">    Latency    61.27ms   62.15ms   1.46s    93.06%</span><br><span class="line">    Req/Sec     9.74k     1.33k   22.11k    71.75%</span><br><span class="line">  Latency Distribution</span><br><span class="line">     50%   48.47ms</span><br><span class="line">     75%   66.32ms</span><br><span class="line">     90%   90.10ms</span><br><span class="line">     99%  364.05ms</span><br><span class="line">  34884275 requests <span class="keyword">in</span> 3.00m, 4.35GB <span class="built_in">read</span></span><br><span class="line">Requests/sec: 193693.29</span><br><span class="line">Transfer/sec:     24.75MB</span><br></pre></td></tr></table></figure><p>测试平台是<code>Intel Core i7-12700H</code>，可以看到并发在<code>1,0000</code>的时候，Gin的性能还是不错的，TPS保持在了19万的水准。</p><h2 id="碎碎念"><a href="#碎碎念" class="headerlink" title="碎碎念"></a>碎碎念</h2><p>该说不该说呢，以前我认为语言就是由语法和编译器&#x2F;解释器构成，但是Golang这样从语法上支持一个feature的行为让我疑惑：语言的标准库该不该算是语言特性的一部分？</p><p><code>go</code>这个关键字作为一个大大的语法糖，似乎在打破语言的库和语言本身的分界线。我也无从知晓这一方向的尽头是什么。</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><a href="https://zhuanlan.zhihu.com/p/609348456">API性能测试指标以及压测方式 - 最难不过二叉树 - 知乎</a></li><li><a href="https://golang.cx/go/golang%E5%8E%8B%E6%B5%8B.html">golang压测</a></li><li><a href="https://www.digitalocean.com/community/tutorials/how-to-benchmark-http-latency-with-wrk-on-ubuntu-14-04">How To Benchmark HTTP Latency with wrk on Ubuntu 14.04 - DigitalOcean</a></li><li><a href="https://stackoverflow.com/questions/15261612/post-request-with-wrk">POST request with wrk? - StackOverflow</a></li><li><a href="https://github.com/gin-gonic/gin/issues/267">Can I disable gin’s stdout? - GitHub Issue</a></li></ul>