<blockquote>
<p><a href="https://github.com/OFA-Sys/OFA">OFA</a><br><a href="https://colab.research.google.com/github/mit-han-lab/once-for-a<hr /><blockquote><p><a href="https://github.com/OFA-Sys/OFA">OFA</a><br><a href="https://colab.research.google.com/github/mit-han-lab/once-for-all/blob/master/tutorial/ofa.ipynb#scrollTo=AUhMWvPdr0Z6">OFA样例</a></p></blockquote><p>又是瞎折腾的一天…  </p><h2 id="一、Linux下搭建"><a href="#一、Linux下搭建" class="headerlink" title="一、Linux下搭建"></a>一、Linux下搭建</h2><p>按照要求搭建即可，没啥特殊的情况，注意把需要的库下载完整。  </p><p>但是我的Linux因为种种原因挂不上N卡，我就换Windows了。</p><h2 id="二、Windows下搭建"><a href="#二、Windows下搭建" class="headerlink" title="二、Windows下搭建"></a>二、Windows下搭建</h2><h3 id="1-torch-cuda-is-available-为False"><a href="#1-torch-cuda-is-available-为False" class="headerlink" title="(1) torch.cuda.is_available()为False"></a>(1) torch.cuda.is_available()为False</h3><p>需要安装Nvidia Toolkit,并且安装特定版本的torch即可。</p><h3 id="2-运行时报错，报错中显示让使用freeze-support"><a href="#2-运行时报错，报错中显示让使用freeze-support" class="headerlink" title="(2) 运行时报错，报错中显示让使用freeze_support()"></a>(2) 运行时报错，报错中显示让使用freeze_support()</h3><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver">RuntimeError: <br>        An attempt has been made <span class="hljs-built_in">to</span> <span class="hljs-built_in">start</span> <span class="hljs-keyword">a</span> <span class="hljs-built_in">new</span> <span class="hljs-built_in">process</span> <span class="hljs-keyword">before</span> <span class="hljs-keyword">the</span><br>        current <span class="hljs-built_in">process</span> has finished its bootstrapping phase.<br>        This probably means that you are <span class="hljs-keyword">not</span> <span class="hljs-keyword">using</span> fork <span class="hljs-built_in">to</span> <span class="hljs-built_in">start</span> your<br>        child processes <span class="hljs-keyword">and</span> you have forgotten <span class="hljs-built_in">to</span> use <span class="hljs-keyword">the</span> proper idiom<br>        <span class="hljs-keyword">in</span> <span class="hljs-keyword">the</span> main module:<br>            <span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>                freeze_support()<br>                ...<br>        The <span class="hljs-string">&quot;freeze_support()&quot;</span> <span class="hljs-built_in">line</span> can be omitted <span class="hljs-keyword">if</span> <span class="hljs-keyword">the</span> program<br>        is <span class="hljs-keyword">not</span> going <span class="hljs-built_in">to</span> be frozen <span class="hljs-built_in">to</span> produce <span class="hljs-keyword">an</span> executable.<br></code></pre></td></tr></table></figure><p>这个是因为Windows和Linux下mutilprocessing实现不同的问题，可以参考下面几个帖子:</p><p><a href="https://github.com/pyinstaller/pyinstaller/wiki/Recipe-Multiprocessing">Recipe-Multiprocessing</a>   </p><p><a href="https://blog.csdn.net/weixin_42316691/article/details/120993311?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522167012141816800186577851%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=167012141816800186577851&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-22-120993311-null-null.142%5Ev67%5Econtrol,201%5Ev3%5Econtrol_1,213%5Ev2%5Et3_esquery_v3&utm_term=windows%20freeze_support&spm=1018.2226.3001.4187">The “freeze_support()“ line can be omitted if the program</a>   </p><p><a href="https://blog.csdn.net/weixin_47269200/article/details/115443949?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522167012141816800186577851%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=167012141816800186577851&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-21-115443949-null-null.142%5Ev67%5Econtrol,201%5Ev3%5Econtrol_1,213%5Ev2%5Et3_esquery_v3&utm_term=windows%20freeze_support&spm=1018.2226.3001.4187">python运行子进程时报错：The “freeze_support()“ line can be omitted if the program is not going to be froze</a>   </p><p><a href="https://chtalhaanwar.medium.com/pytorch-num-workers-a-tip-for-speedy-training-ed127d825db7">PyTorch num_workers, a tip for speedy training</a>   </p><p>最后，我的解决方案就是，<strong>根据报错修改OFA库源码内涉及设置num_works的，改为0</strong>，就没有报错了(但是存在负面影响，具体可以看上面的链接)。</p>